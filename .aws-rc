aws_profile() {
  if [ $# -eq 0 ]; then
    echo "$AWS_PROFILE"
  else
    export AWS_PROFILE="$1"
  fi
}
export -f aws_profile
defn awp aws_profile
aws_unset_profile() {
  unset AWS_PROFILE
}
export -f aws_unset_profile
defn awup aws_unset_profile
defn awus aws_unset_profile

defn ec2 aws ec2
defn ecr aws ecr
defn aed aws ec2 describe-instances
defn eis aws ec2 start-instances --instance-ids
defn eip aws ec2 stop-instances --instance-ids
defn eit aws ec2 terminate-instances --instance-ids
defn ecrc aws ecr create-repository --repository-name
defn ecrd aws ecr delete-repository --repository-name
defn s3 aws s3

ec2_instance_start_and_hostname() {
    aws ec2 start-instances --instance-ids "$@"
    for id in "$@"; do
        ec2-ssh-hostname "$id"
    done
}
export -f ec2_instance_start_and_hostname
defn eish ec2_instance_start_and_hostname

aws_help() {
  aws "$@" help
}
export -f aws_help
defn ah aws_help

defn asl aws s3 ls
defn aslh aws s3 ls --human-readable
defn ash aws s3 ls --human-readable
defn aslr aws s3 ls --recursive
aws_s3_ls_recursive() {
    flags=()
    urls=()
    for arg in "$@"; do
        if [ "${arg:0:1}" == "-" ]; then
            flags+=("$arg")
        else
            urls+=("$arg")
        fi
    done
    if which parallel &>/dev/null; then
        parallel aws s3 ls --recursive "${flags[@]}" ::: "${urls[@]}"
    else
        for url in "${urls[@]}"; do
            aws s3 ls --recursive "${flags[@]}" "$arg"
            rv=$?
            if [ $rv -ne 0 ]; then
                return $rv
            fi
        done
    fi
}
export -f aws_s3_ls_recursive
defn alr aws_s3_ls_recursive
defn alh aws s3 ls --recursive --human-readable
defn alrh aws s3 ls --recursive --human-readable

aws_s3_ls_recursive_sizes() {
  aws_s3_ls_recursive "$@" | cut -d' ' -f3-
}
export -f aws_s3_ls_recursive_sizes
defn alrs aws_s3_ls_recursive_sizes

aws_s3_sum_size_human_readable() {
    aws_s3_ls_recursive_sizes "$@" | awk '{print $1}' | jq -s add | numfmt --to=iec
}
export -f aws_s3_sum_size_human_readable
defn ashs aws_s3_sum_size_human_readable

s3_content_type() {
    if [ $# -ne 2 ]; then
        echo "Usage: ${FUNCNAME[0]} [s3://]<bkt>/<key> <content-type>" >&2
        return 1
    fi
    url="$1"; shift
    content_type="$1"; shift
    url="${url#s3://}"
    bkt="${url%%/*}"
    key="${url#*/}"
    echo "bkt: $bkt, key: $key" >&2
    aws s3api copy-object --bucket "$bkt" --content-type "$content_type" \
        --copy-source "$bkt/$key" --key "$key" \
        --metadata-directive "REPLACE"
}
export -f s3_content_type
defn s3ct s3_content_type

instance() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <instance id>" >&2
        return 1
    fi
    aws ec2 describe-instances --instance-ids "$1" \
        | o1 .Reservations \
        | j1 .Instances \
        | j1
}
export -f instance
defn ei instance

instance_name() {
    instance "$@" | jq -r '.Tags[] | select(.Key == "Name") | .Value'
}
export -f instance_name
defn isn instance_name

instance_ebs_volume_ids() {
    instance "$@" | jq -r '.BlockDeviceMappings[].Ebs | select(.) | .VolumeId'
}
defn e2iv instance_ebs_volume_ids

instance_ami() {
    instance "$@" | jq -r .ImageId
}
export -f instance_ami
defn isa instance_ami

# Uses jq `singleton` helper from ../js
instance_security_groups() {
    instance "$@" \
    | jq .NetworkInterfaces | singleton \
    | jq .Groups
}
export -f instance_security_groups
defn isgs instance_security_groups

ec2_list() {
    if [ $# -lt 2 ]; then
        echo "Usage: ${FUNCNAME[0]} <ec2 subcommand> <ids flag> [...ids]" >&2
        return 1
    fi
    subcmd="$1"; shift
    ids_flag="$1"; shift
    if [ $# -eq 0 ]; then
        aws ec2 $subcmd
    else
        if which parallel &>/dev/null; then
            parallel -k "aws ec2 $subcmd --$ids_flag" ::: "$@"
        else
            if [ $# -gt 1 ]; then
                echo 'Invoking `aws ec2 '$subcmd --$ids_flag'` for each of '$#' IDs, to ensure consistent ordering.' >&2
                echo 'Recommend installing GNU Parallel for faster execution.' >&2
            fi
            for id in "$@"; do
                aws ec2 $subcmd --$ids_flag "$id"
            done
        fi
    fi
}
export -f ec2_list

security_group_details() {
    ec2_list describe-security-groups group-ids "$@" \
    | jq '.SecurityGroups[]'
}
export -f security_group_details
defn sgd security_group_details

security_groups() {
    security_group_details "$@" | jq '{ GroupId, GroupName, Description, VpcId }'
}
export -f security_groups
defn sg security_groups

security_group_grep() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <pattern>" >&2
        return 1
    fi
    security_groups | jq 'select(.GroupName | test("'$1'"))'
}
export -f security_group_grep
defn sgg security_group_grep

security_group_delete() {
    for arg in "$@"; do
        if [ "${arg:0:3}" == sg- ]; then
            echo "Deleting security group by ID: $arg" >&2
            aws ec2 delete-security-group --group-id "$arg"
        else
            echo "Deleting security group by name: $arg" >&2
            aws ec2 delete-security-group --group-name "$arg"
        fi
    done
}
export -f security_group_delete
defn sgrm security_group_delete

instance_security_group() {
    instance_security_groups "$@" | singleton
}
export -f instance_security_group
defn isg instance_security_group

instance_security_group_id() {
    instance_security_group "$@" | jq -r '.GroupId'
}
export -f instance_security_group_id
defn isgi instance_security_group_id

instance_security_group_name() {
    instance_security_group "$@" | jq -r '.GroupName'
}
export -f instance_security_group_name
defn isgn instance_security_group_name

defn arm aws s3 rm
defn armr aws s3 rm --recursive
defn armrn aws s3 rm --recursive --dryrun

aws_s3_rm_includes() {
    if [ $# -lt 1 ]; then
        echo "Usage: ${FUNCNAME[0]} [--dryrun] [include...] <src> <dst>" >&2
        return 1
    fi
    local dryrun=
    local includes=()
    while [ $# -gt 1 ]; do
        case "$1" in
            --dryrun) dryrun=--dryrun ;;
            *) includes+=("$1") ;;
        esac
        shift
    done
    base="$1"; shift
    if [ "$base" == s3:// ]; then
        echo "Error: remove-includes from top level of S3 not supported" >&2
        return 1
    fi
    local include_args=()
    for include in "${includes[@]}"; do
        include_args+=(--include "$include")
    done
    cmd=(aws s3 rm --recursive $dryrun --exclude '*' "${include_args[@]}" "$base")
    echo "Running: ${cmd[@]}" >&2
    "${cmd[@]}"
}
export -f aws_s3_rm_includes
defn armi aws_s3_rm_includes
defn armni aws_s3_rm_includes --dryrun

aws_s3_cp() {
    if [ $# -eq 2 ]; then
        aws s3 cp "$@"
    elif [ $# -eq 1 ]; then
        src="$1"; shift
        dst="./$(basename "$src")"; shift
        cmd=(aws s3 cp "$src" "$dst")
        echo "${cmd[*]}" >&2
        "${cmd[@]}"
    elif [ $# -eq 0 ]; then
        echo "Usage: ${FUNCNAME[0]} <src> [...<src>] [dst=./]" >&2
        return 1
    else
        dst="${@:(-1)}"
        srcs=("${@:1:$(($#-1))}")
        for src in "${srcs[@]}"; do
            cmd=(aws s3 cp "$src" "$dst")
            echo "${cmd[*]}" >&2
            "${cmd[@]}"
        done
    fi
}
export -f aws_s3_cp
defn acp aws_s3_cp
defn s3c aws_s3_cp
defn s3cp aws_s3_cp

defn asc aws-s3-cat
defn asy aws s3 sync
defn asyn aws s3 sync --dryrun
defn asz aws s3 sync --size-only
defn asn aws s3 sync --dryrun
defn asnz aws s3 sync --dryrun --size-only
alias asx="aws s3 sync --exclude '*'"
alias aszx="aws s3 sync --size-only --exclude '*'"
alias asxn="aws s3 sync --exclude '*' --dryrun"
alias asnx="aws s3 sync --dryrun --exclude '*'"
alias asnzx="aws s3 sync --dryrun --size-only --exclude '*'"
aws_s3_sync_include() {
    if [ $# -lt 2 ]; then
        echo "Usage: ${FUNCNAME[0]} [--dryrun] [include...] <src> <dst>" >&2
        return 1
    fi
    local dryrun=
    local sizeonly=
    local exact_timestamps=
    local includes=()
    while [ $# -gt 2 ]; do
        case "$1" in
            --dryrun) dryrun=--dryrun ;;
            --size-only) sizeonly=--size-only ;;
            --exact-timestamps) exact_timestamps=--exact-timestamps ;;
            *) includes+=("$1") ;;
        esac
        shift
    done
    src="$1"; shift
    dst="$1"; shift
    if [ "$src" == s3:// ]; then
        new_includes=()
        local bkt=
        if [ ${#includes[@]} -eq 0 ]; then
            echo "Error: Must specify at least one include for top level sync" >&2
            return 1
        fi
        for include in "${includes[@]}"; do
            if [ -z "$bkt" ]; then
                bkt="${include%%/*}"
            elif [ "$bkt" != "${include%%/*}" ]; then
                echo "Error: All includes must be in the same bucket: $bkt vs. $include" >&2
                return 2
            fi
            key="${include#*/}"
            new_includes+=("$key")
        done
        includes=("${new_includes[@]}")
        src="s3://$bkt"
        dst="${dst%/}/$bkt"
    fi
    local include_args=()
    for include in "${includes[@]}"; do
        include_args+=(--include "$include")
    done
    cmd=(aws s3 sync $dryrun $sizeonly $exact_timestamps --exclude '*' "${include_args[@]}" "$src" "$dst")
    echo "Running: ${cmd[@]}" >&2
    "${cmd[@]}"
}
export -f aws_s3_sync_include
alias asi=aws_s3_sync_include
alias asin="aws_s3_sync_include --dryrun"
alias asni="aws_s3_sync_include --dryrun"
alias aszi="aws_s3_sync_include --size-only"
alias aszin="aws_s3_sync_include --dryrun --size-only"
alias asnzi="aws_s3_sync_include --dryrun --size-only"
alias ai="aws_s3_sync_include --dryrun"
alias ain="aws_s3_sync_include --dryrun"
alias ani="aws_s3_sync_include --dryrun"
alias azi="aws_s3_sync_include --size-only"
alias azin="aws_s3_sync_include --dryrun --size-only"
alias anzi="aws_s3_sync_include --dryrun --size-only"
# "When syncing from S3 to localâ€¦ the default behavior is to ignore same-sized items unless the local version is newer than the S3 version." -`aws s3 sync help`
alias ast="aws_s3_sync_include --exact-timestamps"
alias astn="aws_s3_sync_include --exact-timestamps --dryrun"

aws_sync_print_sizes() {
    local src="${@: -2:1}"
    export src
    aws_s3_sync_include --dryrun "$@" | \
    perl -pe 's/.* download: (.*) to .*/\1/' | \
    parallel -k -j0 --env PATH --env src 'size="$(aws s3 ls {} | tr -s " " " " | cut -d" " -f3)"; p={}; p=${p#$src}; printf "%d %s\n" "$size" "${p#/}"'
}
export -f aws_sync_print_sizes
defn asps aws_sync_print_sizes
defn aspz aws_sync_print_sizes --size-only

aws_s3_mirror() {
    aws_s3_sync_include "$@" s3:// s3/
}
export -f aws_s3_mirror
alias asm=aws_s3_mirror
alias asmn="aws_s3_mirror --dryrun"
alias asmz="aws_s3_mirror --sizeonly"
alias asmzn="aws_s3_mirror --sizeonly --dryrun"

aws_ecr_list() {
  aws ecr describe-images --repository-name "$@"
}
export -f aws_ecr_list
defn ael aws_ecr_list

aws_ecr_list_n() {
  n="$1"; shift
  aws ecr describe-images --repository-name "$@" \
  | jq "
    .imageDetails |
    map(select(has(\"imageTags\"))) |
    sort_by(.imagePushedAt) |
    .[-$n:] |
    map({imageDigest,imageTags,imageSizeInBytes,imagePushedAt}) |
    map(.imagePushedAt |= todate)
  "
}
export -f aws_ecr_list_n
defn aen aws_ecr_list_n
defn ae5 aws_ecr_list_n 5
defn ae10 aws_ecr_list_n 10

defn els ecr-layer-sizes.py
defn elsh ecr-layer-sizes.py -h

policy_name_to_arn() {
  aws iam list-policies | jq -r ".Policies[]|select(.PolicyName | contains(\"$1\"))|.Arn"
}
defn pnta policy_name_to_arn

pipelines() {
  aws codepipeline list-pipelines \
  | jq '
    .pipelines
    | map(
      .created |= todate |
      .updated |= todate
    )
  '
}
export -f pipelines

defn jobs aws batch describe-jobs --jobs

check_buckets() {
  git grep 's3://' \
  | perl -ne 'print if s/.*(s3:\/\/[\w\-]+).*/\1/' \
  | sort \
  | uniq \
  | parallel 'aws s3 ls {} &>/dev/null && echo "Success: {}" || echo "Failure: {}"'
}

ec2_instance_details() {
    ec2_list describe-instances instance-ids "$@" \
    | o1 Reservations \
    | jq '.[].Instances[]'
}
export -f ec2_instance_details
defn eid ec2_instance_details

ec2_instances() {
    ec2_instance_details "$@" \
    | jq '
        {
            Name: (if .Tags then .Tags[] | select(.Key == "Name") | .Value else "" end),
            InstanceId,
            PublicDnsName,
            InstanceType,
            KeyName,
            State: .State.Name
        }
        | with_entries(select(.value != "" and .value != null))
    '
}
export -f ec2_instances
defn ei ec2_instances
ec2_instances_running() {
    ec2_instances "$@" | jq 'select(.State == "running")'
}
export -f ec2_instances_running
defn eir ec2_instances_running
defn ecl ec2_instances
defn e2l ec2_instances

ec2_instance_grep() {
    if [ $# -eq 0 ]; then
        pattern="$USER"
    elif [ $# -eq 1 ]; then
        pattern="$1"; shift
    else
        echo "Usage: ${FUNCNAME[0]} [pattern=\$USER]" >&2
        return 1
    fi
    ec2_instances | jq 'select((.Name // "") | test("'$pattern'"))'
}
export -f ec2_instance_grep
defn eig ec2_instance_grep

ec2_volume_details() {
    ec2_list describe-volumes volume-ids "$@" \
    | jq '.Volumes[]'
}
export -f ec2_volume_details
defn evd ec2_volume_details

ec2_volume_size() {
    ec2_volume_details "$@" | jq .Size
}
export -f ec2_volume_size
defn evs ec2_volume_size

ec2_volumes() {
    ec2_volume_details "$@" \
    | jq '
        {
            VolumeId,
            Size,
            State,
            Attachments: [.Attachments[].InstanceId],
            SnapshotId
        }
    '
}
export -f ec2_volumes
defn ev ec2_volumes

ec2_refresh_token() {
    local dir="$HOME/.aws"
    local path="$dir/token"
    if ! [ -f "$path" ] || ! [[ $(find "$path" -mmin -300) ]]; then
        mkdir -p "$dir"
        EC2_TOKEN="$(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600")"
        if [ -z "$EC2_TOKEN" ]; then
            echo "Error fetching EC2 token" >&2
            return 1
        fi
        echo "$EC2_TOKEN" > "$path"
        echo "New EC2 token saved to $path" >&2
    else
        EC2_TOKEN="$(cat "$path")"
    fi
    export EC2_TOKEN
}
export -f ec2_refresh_token
defn ert ec2_refresh_token

ec2_current_instance_metadata() {
    ec2_refresh_token
    local curl=(curl -s -H "X-aws-ec2-metadata-token: $EC2_TOKEN")
    if [ $# -eq 0 ]; then
        echo "Pass one or more of:" >&2
        "${curl[@]}" -s http://169.254.169.254/latest/meta-data >&2
        echo >&2
        return 1
    fi
    for arg in "$@"; do
        "${curl[@]}" http://169.254.169.254/latest/meta-data/$arg
        echo
    done
}
export -f ec2_current_instance_metadata
defn ecm ec2_current_instance_metadata
defn ecim ec2_current_instance_metadata

defn ec2_current_instance_id ec2_current_instance_metadata instance-id
defn eci ec2_current_instance_id
defn ecid ec2_current_instance_id

defn ec2_current_instance_type ec2_current_instance_metadata instance-type
defn ect ec2_current_instance_type
defn ecit ec2_current_instance_type

defn ec2_current_ami_id ec2_current_instance_metadata ami-id
defn eca ec2_current_ami_id
defn ecia ec2_current_ami_id

defn ec2_current_region ec2_current_instance_metadata placement/region
defn ecrg ec2_current_region
defn ecir ec2_current_region

defn ec2_current_zone ec2_current_instance_metadata placement/availability-zone
defn ecz ec2_current_zone
defn ecaz ec2_current_zone
defn eciz ec2_current_zone

ec2_volume_grep() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <pattern>" >&2
        return 1
    fi
    ec2_volumes | jq 'select(.VolumeId | test("'$1'"))'
}
export -f ec2_volume_grep
defn evg ec2_volume_grep

ec2_instance_volume_ids() {
    ec2_instance_details "$@" \
    | jq -r '.BlockDeviceMappings[].Ebs?.VolumeId | select(.)'
}
export -f ec2_instance_volume_ids
defn eivi ec2_instance_volume_ids

ec2_instance_volumes() {
    ec2_volumes "$(ec2_instance_volume_ids "$@")"
}
export -f ec2_instance_volumes
defn eiv ec2_instance_volumes

ec2_dnsname() {
    ec2_instances "$@" | jq -r .PublicDnsName
}
export -f ec2_dnsname
defn edn ec2_dnsname

defn esh ec2-ssh-hostname

ec2_state() {
    aws ec2 describe-instances --instance-ids "$@" | jq '.Reservations[] | .Instances[] | .State'
}
export -f ec2_state
defn e2s ec2_state

watch_ec2_state() {
    watch ec2_state "$@"
}
export -f watch_ec2_state
defn eiw watch_ec2_state

wait_ec2_state() {
    watch ec2_state "$@"
}
export -f wait_ec2_state
defn eiww wait_ec2_state

check_pipeline_execution() {
    usage="get_pipeline_execution [[pipeline_name=\$pipeline_name] pipeline_execution_id=\$pipeline_execution_id]"
    if [ $# -lt 2 ]; then
        if [ -z "$pipeline_name" ]; then
            echo "$usage" >&2
            return 11
        fi
        if [ $# -lt 1 ]; then
            if [ -z "$pipeline_execution_id" ]; then
                echo "$usage" >&2
                return 12
            fi
        else
            pipeline_execution_id="$1"; shift
        fi
    elif [ $# -eq 2 ]; then
        pipeline_name="$1"; shift
        pipeline_execution_id="$1"; shift
    else
        echo "$usage" >&2
        return 13
    fi
    local pipeline_execution="$(aws codepipeline get-pipeline-execution --pipeline-name "$pipeline_name" --pipeline-execution-id "$pipeline_execution_id" | jq .pipelineExecution)"
    echo "$pipeline_execution"
    local status="$(echo "$pipeline_execution" | jq -r .status)"
    if [ "$status" == "InProgress" ]; then
        return 0
    else
        echo 'done!'
        return 1
    fi
}
export -f check_pipeline_execution
defn cpe check_pipeline_execution

start_and_poll_pipeline() {
    if [ $# -eq 0 ]; then
        if [ -z "$pipeline_name" ]; then
            echo "$usage" >&2
            return 11
        fi
    elif [ $# -eq 1 ]; then
        pipeline_name="$1"; shift
    else
        echo "$usage" >&2
        return 12
    fi
    export pipeline_name
    export pipeline_execution_id="$(aws codepipeline start-pipeline-execution --name "$pipeline_name" | tee >(cat >&2) | jq -r '.pipelineExecutionId')"
    sleep 1
    watch -n5 -e check_pipeline_execution
}
export -f start_and_poll_pipeline
defn sapp start_and_poll_pipeline

if which aws_completer &>/dev/null; then
    complete -C "$(which aws_completer)" aws
fi

## Public S3 bucket helpers
# aws s3 mb s3://$bkt
# aws s3api put-bucket-policy --bucket $bkt --policy "$(cat public-bucket-policy.json)"
#
# aws s3api put-bucket-acl --bucket $bkt --acl public-read
# aws s3api put-bucket-website --bucket $bkt --website-configuration file://website.json

aws_make_bucket() {
    last="${@:(($#))}"
    set -- "${@:1:$(($#-1))}"
    if [ "${last#s3://}" == "$last" ]; then
        last="s3://$last"
    fi
    aws s3 mb "$@" "$last"
}
export -f aws_make_bucket
defn amb aws_make_bucket

aws_make_objects_public() {
    for arg in "$@"; do
        suffix="${arg#s3://}"
        bkt="${suffix%%/*}"
        key="${suffix#*/}"
        cmd=(aws s3api put-object-acl --bucket "$bkt" --key "$key" --acl public-read)
        echo "${cmd[*]}" >&2
        "${cmd[@]}"
    done
}
export -f aws_make_objects_public
defn amop aws_make_objects_public
defn apo aws_make_objects_public

aws_get_object_acl() {
    for arg in "$@"; do
        suffix="${arg#s3://}"
        bkt="${suffix%%/*}"
        key="${suffix#*/}"
        cmd=(aws s3api get-object-acl --bucket "$bkt" --key "$key")
        echo "${cmd[*]}" >&2
        "${cmd[@]}"
    done
}
export -f aws_get_object_acl
defn agoa aws_get_object_acl

aws_get_bucket_policy() {
    aws s3api get-bucket-policy --bucket "$1" | jq -r .Policy | jq
}
export -f aws_get_bucket_policy
defn agbp aws_get_bucket_policy

defn agbc aws s3api get-bucket-cors --bucket
aws_put_bucket_cors() {
    bkt="$1"; shift
    if [ $# -eq 0 ]; then
        cors_config='{"CORSRules":[{"AllowedHeaders":["Authorization"],"AllowedMethods":["GET","HEAD"],"AllowedOrigins":["*"],"ExposeHeaders":["Access-Control-Allow-Origin", "Accept-Ranges", "Content-Range", "Content-Encoding"]}]}'
    else
        cors_config="$1"; shift
    fi
    aws s3api put-bucket-cors --bucket "$bkt" --cors-configuration "$cors_config" "$@"
}
export -f aws_put_bucket_cors
defn apbc aws_put_bucket_cors

aws_make_bucket_public() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <bkt>" >&2
        return 1
    fi
    b="$1"; shift

    public_access_cmd=(aws s3api put-public-access-block --bucket $b --public-access-block-configuration "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false")
    echo "Running: ${public_access_cmd[*]}" >&2
    "${public_access_cmd[@]}"

    policy="{\"Id\":\"s3://$b-public\",\"Statement\":[{\"Sid\":\"s3://$b-public\",\"Action\":[\"s3:GetObject\"],\"Effect\":\"Allow\",\"Resource\":\"arn:aws:s3:::$b/*\",\"Principal\":{\"AWS\":[\"*\"]}},{\"Sid\":\"s3://$b-public-list\",\"Action\":[\"s3:ListBucket\"],\"Effect\":\"Allow\",\"Resource\":\"arn:aws:s3:::$b\",\"Principal\":{\"AWS\":[\"*\"]}}]}"
    policy_cmd=(aws s3api put-bucket-policy --bucket $b --policy)
    echo "Running: ${policy_cmd[*]} '$(echo "$policy" | jq)'" >&2
    policy_cmd+=("$policy")
    "${policy_cmd[@]}"

    # See also:
    # - aws s3api put-bucket-website --bucket $bkt --website-configuration file://website.json
    # - aws s3api put-bucket-acl --bucket $b --acl public-read
}
export -f aws_make_bucket_public
defn ambp aws_make_bucket_public

pipeline_executions() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <pipeline name>" >&2
    fi
    aws codepipeline list-pipeline-executions --pipeline-name "$1" \
    | jq \
        ' .pipelineExecutionSummaries
        | map(.startTime |= todate)
        | map(.lastUpdateTime |= todate)
        '
}
export -f pipeline_executions
defn pes pipeline_executions

defn cdb codebuild.py
defn cbp codebuild.py projects -v
defn cbpl codebuild.py projects list
defn cbplv codebuild.py projects list -v
defn cbb codebuild.py builds
defn cbbl codebuild.py builds latest
defn cbblv codebuild.py builds latest -v
defn cbbls codebuild.py builds list
defn cbblsv codebuild.py builds list -v
defn cbblsvv codebuild.py builds list -vv
defn cbbg codebuild.py builds logs

defn cpl codepipeline.py list
defn cplv codepipeline.py list -v
defn cpel codepipeline.py executions list
defn cpelv codepipeline.py executions list -v
defn cpelvh codepipeline.py executions list -vn10
defn cpelvv codepipeline.py executions list -vv
defn cpelvv1 codepipeline.py executions list -vvn1

defn ed2t ecr-digest-to-tags

defn tfn terraform
defn tfa terraform apply
defn tfd terraform destroy
defn tfi terraform init
defn tfp terraform plan
defn tfpo terraform plan -o

defn awai aws sts get-caller-identity
defn agci aws sts get-caller-identity
aws_account() {
    aws sts get-caller-identity | jq -r .Account
}
export -f aws_account
defn awa aws_account
defn aws_region aws configure get region
defn agr aws configure get region
defn awr aws configure get region
defn awsr aws configure set region

ami() {
    if [ $# -eq 1 ]; then
        ami_id="$1"; shift
        aws ec2 describe-images --image-ids "$ami_id" | jq '.Images[0]'
    else
        aws ec2 describe-images --image-ids "$@"
    fi
}
export -f ami

amin() {
    ami "$@" | jq -r .Name
}
export -f amin

amibdm() {
    if [ $# -eq 1 ]; then
        ami "$@" | jq .BlockDeviceMappings
    else
        ami "$@" | jq '.Images[] | {ImageId, BlockDeviceMappings}'
    fi
}
export -f amibdm

ami_ebs_mount() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <ami id>" >&2
        return 1
    fi
    if [[ "$1" == i-* ]]; then
        instance_id="$1"; shift
        ami_id="$(instance_ami "$instance_id")"
    else
        ami_id="$1"; shift
    fi
    amibdm "$ami_id" | jq '.[] | select(has("Ebs"))' | j1rs .DeviceName
}
export -f ami_ebs_mount
defn aem ami_ebs_mount

ami_filter() {
    if [ $# -ne 2 ]; then
        echo "Usage: ${FUNCNAME[0]} <Name> <Values>" >&2
        return 1
    fi
    Name="$1"; shift
    Values="$1"; shift
    aws ec2 describe-images --filter "Name=$Name,Values=$Values"
}
export -f ami_filter
defn amif ami_filter

ami_name_to_id() {
    if [ $# -ne 1 ]; then
        echo "Usage: ${FUNCNAME[0]} <Name>" >&2
        return 1
    fi
    name="$1"; shift
    ami_filter name "$name" | jq -r '.Images[].ImageId'
}
export -f ami_name_to_id
defn amin2i ami_name_to_id

ubuntu_ami() {
    # Adapted from: https://documentation.ubuntu.com/aws/en/latest/aws-how-to/instances/find-ubuntu-images/
    # Also useful: https://cloud-images.ubuntu.com/locator/ec2/
    local version="${1:-22.04}"; shift
    local arch="${1:-amd64}"; shift
    aws ssm get-parameters --names /aws/service/canonical/ubuntu/server/$version/stable/current/$arch/hvm/ebs-gp2/ami-id | jq -r '.Parameters[0].Value'
}
export -f ubuntu_ami
defn uami ubuntu_ami

defn ads aws cloudformation describe-stacks
aws_stack_names() {
    aws cloudformation describe-stacks | jq -r '.Stacks[].StackName'
}
export -f aws_stack_names
defn adsn aws_stack_names

defn ab aws batch
defn abjq aws batch describe-job-queues
aws_batch_job_queue_names() {
    aws batch describe-job-queues "$@" | jq -r '.jobQueues[].jobQueueName'
}
export -f aws_batch_job_queue_names
defn abjqn aws_batch_job_queue_names

defn abjd aws batch describe-job-definitions
defn abjda aws batch describe-job-definitions --status ACTIVE
aws_batch_job_definition_names() {
    aws batch describe-job-definitions "$@" | jq -r '.jobDefinitions[].jobDefinitionName'
}
export -f aws_batch_job_definition_names
defn abjdn aws_batch_job_definition_names
defn abjdan aws_batch_job_definition_names --status ACTIVE

defn abj aws batch list-jobs --job-queue

defn ecs aws ecs

ecs_list_clusters() {
    aws ecs list-clusters | jq -r '.clusterArns[]'
}
export -f ecs_list_clusters
defn ecslc ecs_list_clusters

ecs_running_clusters() {
    local ecs_clusters="$(aws ecs list-clusters | jr '.clusterArns[]')"
    # echo $ecs_clusters
    aws ecs describe-clusters --cluster $ecs_clusters | \
    jq '.clusters[]|{clusterName,registeredContainerInstancesCount}|select(.registeredContainerInstancesCount > 0)'
}
export -f ecs_running_clusters
defn ecsrc ecs_running_clusters

ecs_list_container_instances() {
    aws ecs list-container-instances --cluster "$@" | jq -r '.containerInstanceArns[]'
}
export -f ecs_list_container_instances
defn ecslci ecs_list_container_instances

ecs_describe_container_instances() {
    local prefix="${1%%/*}"
    prefix="${prefix%:container-instance}:cluster"
    local cluster="${1%/*}"
    cluster="$prefix/${cluster#*/}"
    echo "cluster: $cluster" >&2
    aws ecs describe-container-instances --cluster "$cluster" --container-instances "$@"
}
export -f ecs_describe_container_instances
defn ecsdci ecs_describe_container_instances

instances_by_mem() {
    if [ $# -eq 0 ] || [ $# -gt 2 ]; then
        echo "Usage: ${FUNCNAME[0]} <GiB> [cache-file]" >&2
    fi
    gib="$1"; shift
    mib="$(echo "$gib * 1024" | bc)"
    if [ $# -gt 0 ]; then
        out="$1"; shift
    else
        out=/dev/stdout
    fi
    aws ec2 describe-instance-types --query "InstanceTypes[?MemoryInfo.SizeInMiB==\`$mib\`]" --output json | jq . > "$out"
}
export -f instances_by_mem
defn aibm instances_by_mem

summarize_instances() {
    if [ $# -eq 0 ] || [ $# -gt 2 ]; then
        echo "Usage: ${FUNCNAME[0]} <cpus> [arch]" >&2
        return 1
    fi
    local cpus="$1"; shift
    local arch=
    if [ $# -gt 0 ]; then
        arch="$1"; shift
    fi

    select=".cpus == $cpus"
    if [ -n "$arch" ]; then
        select+=" and .archs == [\"$arch\"]"
    fi

    cat | jq -c "map({
        name: .InstanceType,
        cpus: .VCpuInfo.DefaultVCpus,
        archs: .ProcessorInfo.SupportedArchitectures
    })[] | select($select)" | sort
}
export -f summarize_instances
defn aisi summarize_instances

mnt_nvme() {
    if [ $# -ne 2 ]; then
        echo "Usage: ${FUNCNAME[0]} <device> <mountpoint>" >&2
        return 1
    fi
    device="$1"; shift
    mnt="$1"; shift
    sudo mkfs.ext4 "$device"
    sudo mkdir -p "$mnt"
    sudo mount "$device" "$mnt"
    sudo chown -R $USER:$USER "$mnt"
}

defn eil launch_instance.py

vpcs() {
    aws ec2 describe-vpcs | jq '.Vpcs[]'
}
vpc_ids() {
    vpcs | jq -r '.VpcId'
}
defn vpci vpc_ids
vpcs0() {
    vpcs | jq -c '{VpcId, CidrBlock, IsDefault}'
}
defn vp0 vpcs0
default_vpc() {
    vpcs | jq 'select(.IsDefault)'
}
defn dvpc default_vpc
default_vpc_id() {
    default_vpc | jq -r '.VpcId'
}
defn dvpci default_vpc_id

ec2_instance_set_security_group() {
    if [ $# -ne 2 ]; then
        echo "Usage: ${FUNCNAME[0]} <instance id> <security group id>" >&2
        return 1
    fi
    instance_id="$1"; shift
    security_group_id="$1"; shift
    aws ec2 modify-instance-attribute --instance-id "$instance_id" --groups "$security_group_id"
}
defn e2isg ec2_instance_set_security_group
defn isg ec2_instance_set_security_group

defn e2ti aws ec2 terminate-instances --instance-ids
defn e2asgi add_security_group_ingress.py
defn asgi add_security_group_ingress.py

append_to_path ec2

ec2_key_pairs() {
    aws ec2 describe-key-pairs | jq -r '.KeyPairs[].KeyName'
}
export -f ec2_key_pairs
defn ek ec2_key_pairs
defn ekl ec2_key_pairs

alias ekrm='aws ec2 delete-key-pair --key-name'

ec2_keypair_grep() {
    ec2_key_pairs | grep "$@"
}
export -f ec2_keypair_grep
defn ekg ec2_keypair_grep

ecr_login() {
    account="$(aws_account)"
    region="$(aws configure get region)"
    if [ -z "$region" ]; then
        echo "Couldn't find an AWS region ("'`aws configure get region`'")" >&2
        return 1
    fi
    aws ecr get-login-password --region "$region" | docker login --username AWS --password-stdin "$account.dkr.ecr.$region.amazonaws.com"
    aws ecr get-login-password | docker login --username AWS --password-stdin "$@"
}
export -f ecr_login
defn ecrl ecr_login

aws_mfa_arn() {
    aws iam list-mfa-devices | o1 MFADevices | j1r .SerialNumber
}
export -f aws_mfa_arn
defn amfa aws_mfa_arn

aws_get_mfa_creds() {
    if [ $# -ne 1 ]; then
        echo "Usage: aws_get_mfa_creds <MFA code>" >&2
        return 1
    fi
    code="$1"; shift
    mfa_arn="$(aws_mfa_arn)"
    if [ -z "$mfa_arn" ]; then
        echo "No MFA device found" >&2
        return 1
    fi
    aws sts get-session-token --serial-number "$mfa_arn" --token-code "$code" | jq .Credentials
}

aws_mfa_login() {
    local verbose=
    if [ "$1" == "-v" ]; then
        verbose=1
        shift
    fi
    if [ $# -ne 1 ]; then
        echo "Usage: aws_mfa_login [-v] <MFA code>" >&2
        return 1
    fi
    _aws_mfa_login_log() {
        if [ -n "$verbose" ]; then
            echo "$@" >&2
        fi
    }
    local log=_aws_mfa_login_log
    _aws_mfa_login_unset() {
        if [ -n "$2" ]; then
            $log "Unsetting: $1=$2"
            unset $1
        fi
    }
    local unset=_aws_mfa_login_unset
    _aws_creds_log() {
      $log "$@"
      echo "$@" >> ~/.aws/.env
    }
    local flog=_aws_creds_log
    $unset AWS_ACCESS_KEY_ID "$AWS_ACCESS_KEY_ID"
    $unset AWS_SECRET_ACCESS_KEY "$AWS_SECRET_ACCESS_KEY"
    $unset AWS_SESSION_TOKEN "$AWS_SESSION_TOKEN"
    $unset AWS_EXPIRATION "$AWS_EXPIRATION"
    creds="$(aws_get_mfa_creds "$@")"
    if [ -z "$creds" ]; then
        echo "Failed to get MFA credentials" >&2
        return 1
    fi
    export AWS_ACCESS_KEY_ID="$(echo "$creds" | jq -r .AccessKeyId)"
    export AWS_SECRET_ACCESS_KEY="$(echo "$creds" | jq -r .SecretAccessKey)"
    export AWS_SESSION_TOKEN="$(echo "$creds" | jq -r .SessionToken)"
    export AWS_EXPIRATION="$(echo "$creds" | jq -r .Expiration)"
    mkdir -p ~/.aws
    echo > ~/.aws/.env
    $flog "export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID"
    $flog "export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY"
    $flog "export AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN"
    $flog "export AWS_EXPIRATION=$AWS_EXPIRATION"
    unset -f $log
    unset -f $unset
    unset -f $flog
}
export -f aws_mfa_login
defn aml aws_mfa_login
defn amlv aws_mfa_login -v

aws_eval_env() {
    local path="$HOME/.aws/.env"
    if ! [ -f "$path" ]; then
        echo "No $path found" >&2
        return 1
    fi
    eval "$(cat "$path")"
}
export -f aws_eval_env
defn aee aws_eval_env
defn awe aws_eval_env
defn awpe aws_eval_env

aws_cp_env() {
    ssh "$@" "mkdir -p .aws"
    local last="${@: -1}"
    set -- "${@:1:(($# - 1))}"
    cmd=(scp "$@" ~/.aws/.env "$last:.aws/.env")
    echo "${cmd[*]}" >&2
    "${cmd[@]}"
}
export -f aws_cp_env
defn ace aws_cp_env

aws_env_to_credentials() {
    if [ -z "$AWS_ACCESS_KEY_ID" ]; then
        echo "Error: \$AWS_ACCESS_KEY_ID must be set" >&2
        return 1
    fi
    if [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
        echo "Error: \$AWS_SECRET_ACCESS_KEY must be set" >&2
        return 1
    fi
    local dir="$HOME/.aws"
    mkdir -p "$dir"
    local path="$dir/credentials"
    if [ -f "$path" ]; then
        ts="$(date +"%Y-%m-%dT%H:%M:%S")"
        bak="${path}_$ts"
        cmd=(mv "$path" "$bak")
        echo "${cmd[@]}" >&2
        "${cmd[@]}"
    fi
    echo "[default]
aws_access_key_id = $AWS_ACCESS_KEY_ID
aws_secret_access_key = $AWS_SECRET_ACCESS_KEY" > "$path"
    if [ -n "$AWS_SESSION_TOKEN" ]; then
        echo "aws_session_token = $AWS_SESSION_TOKEN" >> "$path"
    fi
}
alias ae2c=aws_env_to_credentials
